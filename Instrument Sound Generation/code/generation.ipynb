{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "class ZScoreNormaliser:\n",
    "    \"\"\"ZScoreNormaliser applies z-score normalization to an array.\"\"\"\n",
    "\n",
    "    def normalise(self, array, mean, std):\n",
    "        norm_array = (array - mean) / std\n",
    "        return norm_array\n",
    "\n",
    "    def denormalise(self, norm_array, mean, std):\n",
    "        array = norm_array * std + mean\n",
    "        return array\n",
    "\n",
    "\n",
    "class SoundGenerator:\n",
    "    \"\"\"SoundGenerator is responsible for generating audios from\n",
    "    spectrograms using a trained VAE model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vae, hop_length, global_mean, global_std):\n",
    "        self.vae = vae\n",
    "        self.hop_length = hop_length\n",
    "        self.global_mean = global_mean\n",
    "        self.global_std = global_std\n",
    "        self._normaliser = ZScoreNormaliser()\n",
    "\n",
    "    def generate(self, spectrograms):\n",
    "        # Generate reconstructed spectrograms and latent representations from the VAE\n",
    "        generated_spectrograms, latent_representations = self.vae.reconstruct(spectrograms)\n",
    "        # Convert spectrograms back to audio signals\n",
    "        signals = self.convert_spectrograms_to_audio(generated_spectrograms)\n",
    "        return signals, latent_representations\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "SPECTROGRAMS_PATH = \"dataset/spectrograms\"\n",
    "# from soundgenerator import SoundGenerator\n",
    "# from autoencoder import VAE\n",
    "# from train import SPECTROGRAMS_PATH\n",
    "\n",
    "# Adjust the working directory if necessary\n",
    "# os.chdir(\"G:/UTS/2024/Spring_2024/Advance Data Algorithm and Machine Learning/DataGeneration-VAE/Instrument Sound Generation\")\n",
    "\n",
    "HOP_LENGTH = 256\n",
    "SAVE_DIR_ORIGINAL = \"samples/original/\"\n",
    "SAVE_DIR_GENERATED = \"samples/generated/\"\n",
    "MEAN_STD_VALUES_PATH = \"dataset/global_mean_std.pkl\"\n",
    "\n",
    "def find_max_shape(spectrograms_path):\n",
    "    max_rows, max_cols = 0, 0\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path)\n",
    "            rows, cols = spectrogram.shape\n",
    "            max_rows = max(max_rows, rows)\n",
    "            max_cols = max(max_cols, cols)\n",
    "    return max_rows, max_cols\n",
    "\n",
    "def load_InstrumentData(spectrograms_path):\n",
    "    x_train = []\n",
    "    file_paths = []\n",
    "    max_rows, max_cols = find_max_shape(spectrograms_path)\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path)  # (n_bins, n_frames)\n",
    "            # Pad or trim spectrogram\n",
    "            padded_spectrogram = np.zeros((max_rows, max_cols))\n",
    "            rows, cols = spectrogram.shape\n",
    "            padded_spectrogram[:rows, :cols] = spectrogram[:max_rows, :max_cols]\n",
    "            x_train.append(padded_spectrogram)\n",
    "            file_paths.append(file_path)\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis]  # Add channel dimension\n",
    "    return x_train, file_paths\n",
    "\n",
    "def select_spectrograms(spectrograms, file_paths, num_spectrograms=2):\n",
    "    sampled_indexes = np.random.choice(range(len(spectrograms)), num_spectrograms, replace=False)\n",
    "    sampled_spectrograms = spectrograms[sampled_indexes]\n",
    "    sampled_file_paths = [file_paths[index] for index in sampled_indexes]\n",
    "    sampled_file_paths = [str(Path(fp).as_posix()) for fp in sampled_file_paths]\n",
    "    return sampled_spectrograms, sampled_file_paths\n",
    "\n",
    "def save_signals(signals, save_dir, filenames, sample_rate=22050):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    for signal, name in zip(signals, filenames):\n",
    "        save_path = os.path.join(save_dir, f\"{name[len('dataset/spectrograms/'):-4]}.wav\")\n",
    "        sf.write(save_path, signal, sample_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\UTS\\\\2024\\\\Spring_2024\\\\Advance Data Algorithm and Machine Learning\\\\DataGeneration-VAE\\\\SoundGeneration_Z'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('g:\\\\UTS\\\\2024\\\\Spring_2024\\\\Advance Data Algorithm and Machine Learning\\\\DataGeneration-VAE\\\\SoundGeneration_Z')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIO Generated!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load global mean and std\n",
    "with open(MEAN_STD_VALUES_PATH, \"rb\") as f:\n",
    "    mean_std_values = pickle.load(f)\n",
    "    global_mean = mean_std_values['mean']\n",
    "    global_std = mean_std_values['std']\n",
    "\n",
    "\n",
    "def convert_spectrograms_to_audio(spectrograms):\n",
    "    normaliser = ZScoreNormaliser()\n",
    "    signals = []\n",
    "    for spectrogram in spectrograms:\n",
    "        # Remove the channel dimension if present\n",
    "        if spectrogram.ndim == 3:\n",
    "            spectrogram = spectrogram[:, :, 0]\n",
    "        # Denormalize the spectrogram using the global mean and std\n",
    "        denorm_log_spec = normaliser.denormalise(\n",
    "            spectrogram, global_mean, global_std)\n",
    "        # Convert from log spectrogram (dB) to linear magnitude spectrogram\n",
    "        spec = librosa.db_to_amplitude(denorm_log_spec)\n",
    "        # Reconstruct the time-domain signal using the Griffin-Lim algorithm\n",
    "        # signal = librosa.istft(spec, hop_length=HOP_LENGTH)\n",
    "        signal = librosa.griffinlim(spec, hop_length=HOP_LENGTH, n_iter=64)\n",
    "\n",
    "        # Append the signal to the list\n",
    "        signals.append(signal)\n",
    "    return signals\n",
    "\n",
    "# Load spectrograms and file paths\n",
    "specs, file_paths = load_InstrumentData(SPECTROGRAMS_PATH)\n",
    "\n",
    "# Sample spectrograms\n",
    "sampled_specs, sampled_file_paths = select_spectrograms(\n",
    "    specs, file_paths, num_spectrograms=10\n",
    ")\n",
    "\n",
    "\n",
    "# Convert original spectrogram samples to audio\n",
    "original_signals = convert_spectrograms_to_audio(spectrograms=sampled_specs)\n",
    "\n",
    "# Save audio signals\n",
    "save_signals(original_signals, SAVE_DIR_ORIGINAL, sampled_file_paths)\n",
    "print(\"AUDIO Generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str = 'dataset/spectrograms/Piano_55.npy'\n",
    "# print(str[len('dataset/spectrograms/'):-4])\n",
    "# print(len('dataset/spectrograms/')) #->> 21"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
